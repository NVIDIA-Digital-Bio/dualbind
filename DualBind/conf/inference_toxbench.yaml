defaults:
  - train_toxbench.yaml
  - _self_

ckpt_path_list: ['path/to/your/checkpoint'] # paths to the trained checkpoint
prediction_csv: path/to/your/output/prediction.csv # output path to predictions

data:
  batch_size: 96
  num_workers: 32
  raw_data_path_csv: path/to/your/dataset/dataset.csv # csv file that has the paths to raw training data
  data_prefix_path: path/to/your/dataset # prefix for the paths in the above csv file

model:
  hidden_size: 256 # number of hidden dimensions
  mpn_depth: 3 # depth of the message passing network
  num_heads: 4 # number of attention heads in the Transformer encoder layer
  dropout: 0.1 # dropout rate
  threshold: 10.0 # distance cutoff threshold
  vocab_size: 38 # number of atom types, vocab_size=len(ATOM_TYPES)
  aa_size: 21 # number of residue types, aa_size=len(ALPHABET)
  max_residue_atoms: 14 # max number of residue atoms
  eps_scaling: true # use esp scaling technique in the DSM loss
  use_mtl_loss: false  # use MTLLoss implementation with adaptive params

trainer:
  num_nodes: 1
  devices: 1 # Only single GPU is supported for inference
